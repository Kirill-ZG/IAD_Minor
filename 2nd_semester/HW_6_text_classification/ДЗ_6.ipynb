{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 6: классификация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом домашнем задании вам предстоит построить классификатор текстов!\n",
    "\n",
    "Данные мы будем использовать из Kaggle соревнования: https://www.kaggle.com/competitions/nlp-getting-started/data Оттуда надо скачать файл train.csv. На обучающую и тестовую выборки его поделим кодом ниже, менять его не надо!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем работать с датасетом постов из твиттера. Нам предстоит решать задачу бинарной классификации - определять содержатся ли в твитте информация о настоящей катастрофе/инциденте или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/User/Майнор ИАД/2 семестр/Домашки/ДЗ_6/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train, test = train_test_split(data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 (0.5 балла)\n",
    "\n",
    "Выведете на экран информацию о пропусках в данных. Если пропуски присутствуют заполните их пустой строкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1                   Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4                              Forest fire near La Ronge Sask. Canada   \n",
       "2   5                   All residents asked to 'shelter in place' are ...   \n",
       "3   6                   13,000 people receive #wildfires evacuation or...   \n",
       "4   7                   Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 (1 балл)\n",
    "Давайте немного посмотрим на наши данные. Визуализируйте (где явно просят) или выведете информацию о следующем:\n",
    "\n",
    "1. Какое распределение классов в обучающей выборке?\n",
    "2. Посмотрите на колонку \"keyword\" - возьмите 10 наиболее встречающихся значений, постройте ступенчатую диаграмму распределения классов в зависимости от значения keyword, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['count'] = np.ones_like(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data.groupby('keyword')['count'].sum().sort_values(ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword\n",
       "               61\n",
       "fatalities     45\n",
       "deluge         42\n",
       "armageddon     42\n",
       "sinking        41\n",
       "damage         41\n",
       "harm           41\n",
       "body%20bags    41\n",
       "evacuate       40\n",
       "fear           40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_index = a.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = data.groupby('keyword')['target'].sum()[list_index] / data.groupby('keyword')['count'].sum()[list_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.688525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fatalities</th>\n",
       "      <td>0.577778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deluge</th>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>armageddon</th>\n",
       "      <td>0.119048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinking</th>\n",
       "      <td>0.195122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>damage</th>\n",
       "      <td>0.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harm</th>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body%20bags</th>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evacuate</th>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "keyword              \n",
       "             0.688525\n",
       "fatalities   0.577778\n",
       "deluge       0.142857\n",
       "armageddon   0.119048\n",
       "sinking      0.195122\n",
       "damage       0.463415\n",
       "harm         0.097561\n",
       "body%20bags  0.024390\n",
       "evacuate     0.625000\n",
       "fear         0.125000"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['keyword'] = b.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.rename(columns={0: 'proportion'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proportion</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.688525</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fatalities</th>\n",
       "      <td>0.577778</td>\n",
       "      <td>fatalities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deluge</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>deluge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>armageddon</th>\n",
       "      <td>0.119048</td>\n",
       "      <td>armageddon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinking</th>\n",
       "      <td>0.195122</td>\n",
       "      <td>sinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>damage</th>\n",
       "      <td>0.463415</td>\n",
       "      <td>damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harm</th>\n",
       "      <td>0.097561</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body%20bags</th>\n",
       "      <td>0.024390</td>\n",
       "      <td>body%20bags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evacuate</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>evacuate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             proportion      keyword\n",
       "keyword                             \n",
       "               0.688525             \n",
       "fatalities     0.577778   fatalities\n",
       "deluge         0.142857       deluge\n",
       "armageddon     0.119048   armageddon\n",
       "sinking        0.195122      sinking\n",
       "damage         0.463415       damage\n",
       "harm           0.097561         harm\n",
       "body%20bags    0.024390  body%20bags\n",
       "evacuate       0.625000     evacuate\n",
       "fear           0.125000         fear"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Распределение классов в зависимости от keyword')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(figsize = (12, 5))\n",
    "plt.step(x='keyword', y='proportion', data=b)\n",
    "plt.xlabel('Keyword')\n",
    "plt.ylabel('Доля класса 1')\n",
    "plt.title('Распределение классов в зависимости от keyword')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 (0.5 балла) \n",
    "\n",
    "В этом задании предлагается объединить все три текстовых столбца в один (просто сконкатенировать cтроки) и убрать столбец с индексом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1                   Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4                              Forest fire near La Ronge Sask. Canada   \n",
       "2   5                   All residents asked to 'shelter in place' are ...   \n",
       "3   6                   13,000 people receive #wildfires evacuation or...   \n",
       "4   7                   Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  count  \n",
       "0       1      1  \n",
       "1       1      1  \n",
       "2       1      1  \n",
       "3       1      1  \n",
       "4       1      1  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('id', axis=1, inplace=True)\n",
    "data.drop('count', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['keyword_location_text'] = data.keyword + ' ' + data.location + ' ' + data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('keyword', axis=1, inplace=True)\n",
    "data.drop('location', axis=1, inplace=True)\n",
    "data.drop('text', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>keyword_location_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to 'shelter in place' ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive #wildfires evacuation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                              keyword_location_text\n",
       "0       1    Our Deeds are the Reason of this #earthquake...\n",
       "1       1             Forest fire near La Ronge Sask. Canada\n",
       "2       1    All residents asked to 'shelter in place' ar...\n",
       "3       1    13,000 people receive #wildfires evacuation ...\n",
       "4       1    Just got sent this photo from Ruby #Alaska a..."
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4 (0.5 балла)\n",
    "\n",
    "Далее мы будем пока работать только с train частью.\n",
    "\n",
    "1. Предобработайте данные (train часть) с помощью CountVectorizer.\n",
    "2. Какого размера получилась матрица?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5329, 2)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>keyword_location_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>0</td>\n",
       "      <td>bridge%20collapse  Ashes 2015: AustraliaÛªs c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>1</td>\n",
       "      <td>hail Carol Stream, Illinois GREAT MICHIGAN TEC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>1</td>\n",
       "      <td>police Houston  CNN: Tennessee movie theater s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>1</td>\n",
       "      <td>rioting  Still rioting in a couple of hours le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7445</th>\n",
       "      <td>0</td>\n",
       "      <td>wounds Lake Highlands Crack in the path where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>0</td>\n",
       "      <td>obliteration Merica! @Eganator2000 There aren'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0</td>\n",
       "      <td>panic  just had a panic attack bc I don't have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0</td>\n",
       "      <td>blood  Omron HEM-712C Automatic Blood Pressure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>1</td>\n",
       "      <td>Officials say a quarantine is in place at an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>1</td>\n",
       "      <td>whirlwind Stamford &amp; Cork (&amp; Shropshire) I mov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5329 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                              keyword_location_text\n",
       "1186       0  bridge%20collapse  Ashes 2015: AustraliaÛªs c...\n",
       "4071       1  hail Carol Stream, Illinois GREAT MICHIGAN TEC...\n",
       "5461       1  police Houston  CNN: Tennessee movie theater s...\n",
       "5787       1  rioting  Still rioting in a couple of hours le...\n",
       "7445       0  wounds Lake Highlands Crack in the path where ...\n",
       "...      ...                                                ...\n",
       "5226       0  obliteration Merica! @Eganator2000 There aren'...\n",
       "5390       0  panic  just had a panic attack bc I don't have...\n",
       "860        0  blood  Omron HEM-712C Automatic Blood Pressure...\n",
       "7603       1    Officials say a quarantine is in place at an...\n",
       "7270       1  whirlwind Stamford & Cork (& Shropshire) I mov...\n",
       "\n",
       "[5329 rows x 2 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(train.keyword_location_text) # bow — bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5329, 18455)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5 (1 балл)\n",
    "\n",
    "В предыдущем пункте у вас должна была получиться достаточно большая матрица.\n",
    "Если вы взгляните на текст, то увидете, что там есть множество специальных символов, ссылок и прочего мусора.\n",
    "\n",
    "Давайте также посмотрим на словарь, который получился в результате построения CountVectorizer, его можно найти в поле vocabulary_ инстанса этого класса. Давайте напишем функцию, которая печает ответы на следующие вопросы:\n",
    "\n",
    "1. Найдите в этом словаре все слова, которые содержат цифры. Сколько таких слов нашлось?\n",
    "\n",
    "2. Найдите все слова, которые содержат символы пунктуации. Сколько таких слов нашлось? \n",
    "\n",
    "3. Сколько хэштегов (токен начинается на #) и упоминаний (токен начинается на @) осталось в словаре?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = list(vec.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_numbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "\n",
    "\n",
    "def ispunct(a):\n",
    "    if a in string.punctuation:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "    \n",
    "def is_dog(a):\n",
    "    if a == '@':\n",
    "        return True\n",
    "    elif a == '#':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def has_punctuation(inputString):\n",
    "    return any(ispunct(char) for char in inputString)\n",
    "\n",
    "\n",
    "def has_dog(inputString):\n",
    "    return any(is_dog(char) for char in inputString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function5(vocabulary):\n",
    "    count_num = 0\n",
    "    for t in vocabulary:\n",
    "        if has_numbers(t[0]):\n",
    "            count_num += 1\n",
    "    \n",
    "    count_punct = 0\n",
    "    for t in vocabulary:\n",
    "        if has_punctuation(t[0]):\n",
    "            count_punct += 1\n",
    "    \n",
    "    count_dog = 0\n",
    "    for t in vocabulary:\n",
    "        if has_dog(t[0]):\n",
    "            count_dog += 1\n",
    "    \n",
    "    return (count_num, count_punct, count_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3812, 315, 0)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function5(voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6 (0.5 балла)\n",
    "\n",
    "Вспомним, что на семинаре по текстам мы узнали, что в nltk есть специальный токенизатор для текстов - TweetTokenizer. Попробуем применить CountVectorizer с этим токенизатором. Ответьте на все вопросы из предыдущего пункта для TweetTokenizer и сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "# Чтобы узнать, какие параметры есть у этого токенайзера - используйте help(TweetTokenizer)\n",
    "# Для того, чтобы передать токенайзер в CountVectorizer используйте параметр tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tweet = CountVectorizer(ngram_range=(1, 1), tokenizer=tw.tokenize)\n",
    "bow_tweet = vec_tweet.fit_transform(train.keyword_location_text) # bow — bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5329, 19670)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_tweet = list(vec_tweet.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3939, 7338, 3155)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function5(voc_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 7 (2 балла)\n",
    "\n",
    "В scikit-learn мы можем оценивать процесс подсчета матрицы через CountVectorizer. У CountVectorizer, как и у других наследников \\_VectorizerMixin, есть аргумент tokenizer и preprocessor. preprocessor применится в самом начале к каждой строке вашего датасета, tokenizer же должен принять строку и вернуть токены.\n",
    "Давайте напишем кастомный токенайзер, которые сделает все, что нам нужно: \n",
    "\n",
    "0. Приведет все буквы к нижнему регистру\n",
    "1. Разобьет текст на токены с помощью TweetTokenizer из пакета nltk\n",
    "2. Удалит все токены содержащие не латинские буквы, кроме смайликов (будем считать ими токены содержащие только пунктуацию и, как минимум, одну скобочку) и хэштегов, которые после начальной # содержат только латинские буквы.\n",
    "3. Удалит все токены, которые перечислены в nltk.corpus.stopwords.words('english')\n",
    "4. Проведет стемминг с помощью SnowballStemmer\n",
    "\n",
    "Продемонстрируйте работу вашей функции на первых десяти текстах в обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import printable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_latin(text): \n",
    "    return not bool(set(text) - set(printable)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_smilik(inputString):\n",
    "    return any(char == ')' or char == '(' for char in inputString) and all(ispunct(char) for char in inputString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_hashtag(inputString):\n",
    "    return (inputString[0] == '#') and (inputString[1:].isalpha())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['younger', 'vulner', 'year', ':)']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_tokenizer(inputString):\n",
    "    inputString = inputString.lower()\n",
    "    tw = TweetTokenizer()\n",
    "    tokenized_string = tw.tokenize(inputString)\n",
    "    tokenized_string_2 = []\n",
    "    for t in tokenized_string:\n",
    "        if (is_smilik(t) or t.isalpha() or is_hashtag(t)) and not(t in nltk.corpus.stopwords.words('english')):\n",
    "            tokenized_string_2.append(t)\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    tokenized_stemmed = [stemmer.stem(w) for w in tokenized_string_2]\n",
    "    return tokenized_stemmed\n",
    "custom_tokenizer(\"In my younger and more vulnerable years :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1186, 4071, 5461, 5787, 7445, 151, 915, 1305, 2570, 7399], dtype='int64')"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inx_list = train.index[0:10]\n",
    "inx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bridg', 'ash', 'australia', 'ûªs', 'collaps', 'trent', 'bridg', 'among', 'worst', 'histori', 'england', 'bundl', 'australia']\n",
      "['hail', 'carol', 'stream', 'illinoi', 'great', 'michigan', 'techniqu', 'camp', 'thank', '#goblu', '#wrestleon']\n",
      "['polic', 'houston', 'cnn', 'tennesse', 'movi', 'theater', 'shoot', 'suspect', 'kill', 'polic']\n",
      "['riot', 'still', 'riot', 'coupl', 'hour', 'left', 'class']\n",
      "['wound', 'lake', 'highland', 'crack', 'path', 'wipe', 'morn', 'beach', 'run', 'surfac', 'wound', 'left', 'elbow', 'right', 'knee']\n",
      "['airplan', 'somewher', 'expert', 'franc', 'begin', 'examin', 'airplan', 'debri', 'found', 'reunion', 'island', 'french', 'air', 'accid', 'expert', '#mlb']\n",
      "['bloodi', 'isol', 'citi', 'world', 'perth', 'came', 'kill', 'indian', 'fun', 'video', 'smirk', 'remorseless', 'pakistani', 'killer', 'show', 'boast']\n",
      "['burn', 'except', 'idk', 'realli', 'burn']\n",
      "['destroy', '(', 'ask', ')', 'destroy', 'hous']\n",
      "['wound', 'maracay', 'nirgua', 'venezuela', 'polic', 'offic', 'wound', 'suspect', 'dead', 'exchang', 'shot']\n"
     ]
    }
   ],
   "source": [
    "for t in inx_list:\n",
    "    print(custom_tokenizer(train.keyword_location_text[t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 8 (1 балл)\n",
    "\n",
    "1. Примените CountVectorizer с реализованным выше токенизатором к обучающим и тестовым выборкам.\n",
    "2. Обучите LogisticRegression на полученных признаках.\n",
    "3. Посчитайте метрику f1-score на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tweet_custom = CountVectorizer(ngram_range=(1, 1), tokenizer=custom_tokenizer)\n",
    "bow_tweet_custom = vec_tweet_custom.fit_transform(train.keyword_location_text) # bow — bag of words (мешок слов)\n",
    "\n",
    "bow_test_custom = vec_tweet_custom.transform(test.keyword_location_text)\n",
    "\n",
    "#scaler = MaxAbsScaler()\n",
    "#bow_tweet_custom = scaler.fit_transform(bow_tweet_custom)\n",
    "#bow_test_custom = scaler.transform(bow_test_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5329, 10591)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_tweet_custom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_tweet_custom = list(vec_tweet_custom.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      1318\n",
      "           1       0.78      0.72      0.75       966\n",
      "\n",
      "    accuracy                           0.80      2284\n",
      "   macro avg       0.79      0.79      0.79      2284\n",
      "weighted avg       0.80      0.80      0.80      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=200, random_state=42)\n",
    "clf.fit(bow_tweet_custom, train.target)\n",
    "pred = clf.predict(bow_test_custom)\n",
    "print(classification_report(test.target, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 9 (1 балл)\n",
    "\n",
    "1. Повторите 7 задание, но с tf-idf векторизатором. Как изменилось качество?\n",
    "2. Мы можем еще сильнее уменьшить размер нашей матрицы, если отбросим значения df близкие к единице. Скорее всего такие слова не несут много информации о категории, так как встречаются достаточно часто. Ограничьте максимальный df в параметрах TfIdfVectorizer, поставьте верхнюю границу равную 0.9. Как изменился размер матрицы, как изменилось качество?\n",
    "3. Также мы можем уменьшить размер матрицы, удаляя слова со слишком маленьким df. Удалось ли добиться улучшения качества? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tweet_custom_tf = TfidfVectorizer(ngram_range=(1, 1), tokenizer=custom_tokenizer)\n",
    "bow_tweet_custom_tf = vec_tweet_custom_tf.fit_transform(train.keyword_location_text) # bow — bag of words (мешок слов)\n",
    "\n",
    "bow_test_custom_tf = vec_tweet_custom_tf.transform(test.keyword_location_text)\n",
    "\n",
    "\n",
    "#Со скейлерами почему-то хуже)))\n",
    "#scaler = MaxAbsScaler()\n",
    "#bow_tweet_custom_tf = scaler.fit_transform(bow_tweet_custom_tf)\n",
    "#bow_test_custom_tf = scaler.transform(bow_test_custom_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5329x10591 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 51341 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_tweet_custom_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83      1318\n",
      "           1       0.80      0.69      0.74       966\n",
      "\n",
      "    accuracy                           0.80      2284\n",
      "   macro avg       0.80      0.78      0.79      2284\n",
      "weighted avg       0.80      0.80      0.80      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tf = LogisticRegression(max_iter=300, random_state=42)\n",
    "clf_tf.fit(bow_tweet_custom_tf, train.target)\n",
    "pred_tf = clf_tf.predict(bow_test_custom_tf)\n",
    "print(classification_report(test.target, pred_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Качество с TfIdf ухудшилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tweet_custom_tf = TfidfVectorizer(ngram_range=(1, 1), tokenizer=custom_tokenizer, max_df=0.9)\n",
    "bow_tweet_custom_tf = vec_tweet_custom_tf.fit_transform(train.keyword_location_text) # bow — bag of words (мешок слов)\n",
    "\n",
    "bow_test_custom_tf = vec_tweet_custom_tf.transform(test.keyword_location_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "bow_tweet_custom_tf = scaler.fit_transform(bow_tweet_custom_tf)\n",
    "bow_test_custom_tf = scaler.transform(bow_test_custom_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5329x10591 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 51341 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_tweet_custom_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83      1318\n",
      "           1       0.78      0.70      0.74       966\n",
      "\n",
      "    accuracy                           0.79      2284\n",
      "   macro avg       0.79      0.78      0.78      2284\n",
      "weighted avg       0.79      0.79      0.79      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tf = LogisticRegression(max_iter=300, random_state=42)\n",
    "clf_tf.fit(bow_tweet_custom_tf, train.target)\n",
    "pred_tf = clf_tf.predict(bow_test_custom_tf)\n",
    "print(classification_report(test.target, pred_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#При max_df=0.9 качество не поменялось и размер тоже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tweet_custom_tf = TfidfVectorizer(ngram_range=(1, 1), tokenizer=custom_tokenizer, min_df=0.001)\n",
    "bow_tweet_custom_tf = vec_tweet_custom_tf.fit_transform(train.keyword_location_text) # bow — bag of words (мешок слов)\n",
    "\n",
    "bow_test_custom_tf = vec_tweet_custom_tf.transform(test.keyword_location_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "bow_tweet_custom_tf = scaler.fit_transform(bow_tweet_custom_tf)\n",
    "bow_test_custom_tf = scaler.transform(bow_test_custom_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5329x1753 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 37319 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_tweet_custom_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83      1318\n",
      "           1       0.78      0.71      0.74       966\n",
      "\n",
      "    accuracy                           0.79      2284\n",
      "   macro avg       0.79      0.78      0.78      2284\n",
      "weighted avg       0.79      0.79      0.79      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tf = LogisticRegression(max_iter=300, random_state=42)\n",
    "clf_tf.fit(bow_tweet_custom_tf, train.target)\n",
    "pred_tf = clf_tf.predict(bow_test_custom_tf)\n",
    "print(classification_report(test.target, pred_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#При min_df=0.001 качество не поменялось, но размер матрицы уменьшился\n",
    "#И вообще добиться улучшения качества не получается, но получается уменьшить размер матрицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 10 (1 балл)\n",
    "\n",
    "Еще один популяпный трюк, который позволит уменьшить количество признаков называется hashing trick. Его суть в том, то мы случайно группируем признаки ииии  ..... складываем их! А потом удаляем исходные признаки. В итоге все наши признаки это просто суммы исходных. Звучит странно, но это отлично работает. Давайте проверим этот трюк в нашем сеттинге.\n",
    "Также при таком подходе вам не нужно хранить словарь token->index, что тоже иногда полезно.\n",
    "\n",
    "1. Повторите задание 7 с HashingVectorizer, укажите количество фичей равное 5000.\n",
    "2. Какой из подходов показал самый высокий результат?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "vec_tweet_custom = HashingVectorizer(ngram_range=(1, 1), tokenizer=custom_tokenizer, n_features=5000)\n",
    "bow_tweet_custom = vec_tweet_custom.fit_transform(train.keyword_location_text) # bow — bag of words (мешок слов)\n",
    "\n",
    "bow_test_custom = vec_tweet_custom.transform(test.keyword_location_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5329x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 51301 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_tweet_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82      1318\n",
      "           1       0.78      0.67      0.72       966\n",
      "\n",
      "    accuracy                           0.78      2284\n",
      "   macro avg       0.78      0.77      0.77      2284\n",
      "weighted avg       0.78      0.78      0.78      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=200, random_state=42)\n",
    "clf.fit(bow_tweet_custom, train.target)\n",
    "pred = clf.predict(bow_test_custom)\n",
    "print(classification_report(test.target, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Самый высокий результат у обычного CountVectorizer'а)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 11 (1 балл)\n",
    "\n",
    "В этом задании нужно добиться f1 меры хотя в 0.75 на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#получилось в 8ом задании"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
